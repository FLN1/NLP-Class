{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as file:\n",
    "    document = file.read()\n",
    "    doc = nlp(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "len(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The man's hands were behind\n",
       "his back, the wrists bound with a cord.  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det the\n",
      "man NOUN poss man\n",
      "'s PART case 's\n",
      "hands NOUN nsubj hand\n",
      "were AUX ROOT be\n",
      "behind ADP prep behind\n",
      "\n",
      " SPACE dep \n",
      "\n",
      "his PRON poss his\n",
      "back NOUN pobj back\n",
      ", PUNCT punct ,\n",
      "the DET det the\n",
      "wrists NOUN appos wrist\n",
      "bound VERB acl bind\n",
      "with ADP prep with\n",
      "a DET det a\n",
      "cord NOUN pobj cord\n",
      ". PUNCT punct .\n",
      "  SPACE dep  \n"
     ]
    }
   ],
   "source": [
    "# NORMAL SOLUTION:\n",
    "sent = sentences[1]\n",
    "for token in sent:\n",
    "    print(token.text,token.pos_,token.dep_,token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           P.O.S.     Dep           Lemma          \n",
      "------------------------------------------------\n",
      "The             DET        det           the            \n",
      "man             NOUN       poss          man            \n",
      "'s              PART       case          's             \n",
      "hands           NOUN       nsubj         hand           \n",
      "were            AUX        ROOT          be             \n",
      "behind          ADP        prep          behind         \n",
      "\n",
      "               SPACE      dep           \n",
      "              \n",
      "his             PRON       poss          his            \n",
      "back            NOUN       pobj          back           \n",
      ",               PUNCT      punct         ,              \n",
      "the             DET        det           the            \n",
      "wrists          NOUN       appos         wrist          \n",
      "bound           VERB       acl           bind           \n",
      "with            ADP        prep          with           \n",
      "a               DET        det           a              \n",
      "cord            NOUN       pobj          cord           \n",
      ".               PUNCT      punct         .              \n",
      "                SPACE      dep                          \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "print(f'{\"Token\":{14}}  {\"P.O.S.\":{10}} {\"Dep\":{13}} {\"Lemma\":{15}}')\n",
    "print('------------------------------------------------')\n",
    "for token in sent:\n",
    "    print(f'{token.text:{15}} {token.pos_:{10}} {token.dep_:{13}} {token.lemma_:{15}}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "phrase = [\n",
    "    {\"LOWER\": \"swimming\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"LOWER\": \"vigorously\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"Swimming\", [phrase])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12881893835109366681, 1274, 1277), (12881893835109366681, 3609, 3612)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "found_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "for found_match in found_matches:\n",
    "    # found_match[0] is the unique id of the found match\n",
    "    # found_match[1] is where the found match in the doc text begins\n",
    "    # found_match[2] is where the found match in the doc text ends\n",
    "    # 9 and 14 are arbitrary values, it is only selected as offsets to match the given expected output\n",
    "    matches.append(doc[found_match[1]-9:found_match[2]+14])\n",
    "\n",
    "print(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  His brain was as energetic as his arms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(matches[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "By diving I could evade the bullets and, swimming\n",
       "vigorously, reach the bank, take to the woods and get away home.  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_sentence = []\n",
    "for sentence in sentences:\n",
    "    for (id, start,end) in found_matches:\n",
    "        if start > sentence.start and end < sentence.end:\n",
    "            match_sentence.append(sentence)\n",
    "        \n",
    "match_sentence[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The hunted man saw all this over his shoulder; he was now swimming\n",
       "vigorously with the current.  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "match_sentence[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
